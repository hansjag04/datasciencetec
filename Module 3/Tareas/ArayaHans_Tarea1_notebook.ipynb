{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea1_EstadisticaParaCienciaDeLosDatos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jdtaAwa8XzNA"
      },
      "source": [
        "# Estad铆stica para Ciencia de los Datos\n",
        "# Tarea #1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b7yZKbBswGSC"
      },
      "source": [
        "Realice los siguientes ejercicios y env铆e sus respuestas, en un notebook de google colab, a trav茅s de TEC Digital a m谩s tardar el jueves 2 de julio a las 5:00 PM. No se aceptar谩n entregas tard铆as.\n",
        "\n",
        "Desarrolle todos los ejercicios con el mayor nivel de detalle posible. Se espera que el desarrollo algebraico sea formal. No ser谩 v谩lido 煤nicamente dar respuestas en prosa a las preguntas.\n",
        "\n",
        "Para la parte 1 de la tarea es v谩lido entregar las respuestas  como un archivo PDF que sea un escaneo de la soluci贸n en papel de los ejercicios. Los estudiantes son responsables por asegurar que el archivo enviado sea legible.\n",
        "\n",
        "Para la parte 2 de la tarea se espera que el c贸digo pueda ejecutarse con visualizaciones apropiadas, sino no se asignar谩 puntaje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5e6Nc6WZTTmc"
      },
      "source": [
        "## Parte 1\n",
        "\n",
        "1.   Una agencia de bienes ra铆ces tiene una base de datos de propiedades vendidas en la cu谩l rastrearon la cantidad de d铆as que dur贸 en concretarse la venta, adem谩s de su precio de venta (ver tabla). Basado en los datos responda los siguientes apartados. Responda todos los puntos utilizando ecuaciones 煤nicamente.\n",
        "\n",
        " * Si $A$ es el evento de vender una casa en m谩s de 90 d铆as, estime la probabilidad de $A$ (5 puntos)\n",
        " * Si $B$ es el evento de vender una casa en menos de 50,000, estime la probablidad de $B$ (5 puntos)\n",
        " * 驴Cu谩l es la probabilidad de que $A$ y $B$ ocurran juntos? (5 puntos)\n",
        " * Si una casa se define que tiene un precio de menos de \\$50,000, 驴cu谩l es la probabilidad que tarde 90 o menos d铆as en venderse? (5 puntos)\n",
        " * 驴Se puede considerar que los eventos $A$ y $B$ son independientes? (Demu茅strelo matem谩ticamente) (10 puntos)\n",
        "  \n",
        "|| Menos de 30 d铆as | De 31 a 90 | M谩s de 90 | Total\n",
        "|--- | --- | --- | --- |---\n",
        "|**Menos de \\$50,000**|50|40|10|100\n",
        "|**50,000 a 99,999**|20|150|80|250\n",
        "|**100,000 a 149,999**|20|280|100|400\n",
        "|**M谩s de 150,000**|10|10|30|50\n",
        "|**Total**|100|480|220|800\n",
        "\n",
        "\n",
        "\n",
        "2.   Suponga que se desea analizar la relaci贸n entre tres variables aleatorias $X_{1},X_{2}$ y $X_{3}$, para las cuales se han recabado los siguientes arreglos de $N=3$ observaciones:\n",
        " * Calcule la varianza de cada variable aleatoria (muestre todos los pasos) (10 puntos)\n",
        " * Calcule la matriz de correlaci贸n de Pearson (muestre todos los pasos) (10 puntos)\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{array}{c}\n",
        "h_{1}=\\begin{bmatrix}3 & 15 & 21\\end{bmatrix}\\\\\n",
        "h_{2}=\\begin{bmatrix}1 & 5 & 6\\end{bmatrix}\\\\\n",
        "h_{3}=\\begin{bmatrix}13 & 7 & 3\\end{bmatrix}\n",
        "\\end{array}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnoBDmRMlbVG",
        "colab_type": "text"
      },
      "source": [
        "### R/\n",
        "\n",
        "La parte 1 fue realizada en papel y se adjunta en el **.zip** de la tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "chgbdVm7TbL-"
      },
      "source": [
        "## Parte 2\n",
        "\n",
        "1. Muestreo de estaturas. Los estudiantes deber谩n programar dos funciones para crear muestras de $N$ personas (observaciones) con una sola variable aleatoria: estatura. Para efectos pr谩cticos, ambas funciones pueden retornar una simple lista con valores num茅ricos que representan la estatura en cent铆metros de diferentes personas. Para ambas funciones deber谩n mostrarse ejemplos de creaci贸n de muestras con al menos 100 observaciones y mostrarlas en un histograma. La cantidad de cubetas deber谩 limitarse a un m谩ximo de 9. Las funciones a programar ser谩n las siguientes:\n",
        " * **Muestreo Uniforme**. Adem谩s de recibir la cantidad de observaciones a generar $N$, recibir谩 la estatura m铆nima y m谩xima  por par谩metro. Por ejemplo, si se pide una distribuci贸n uniforme entre 150 y 168, las estaturas entre ese rango deber谩n ser igual de probables de muestrear. (5 puntos)\n",
        "  * **Muestreo Normal**. Adem谩s de recibir la cantidad de observaciones a generar $N$, recibir谩 la media y desviaci贸n est谩ndar por par谩metro. De esta forma, la funci贸n generar谩 $N$ observaciones provenientes de una distribuci贸n Gaussiana con la media y desviaci贸n est谩ndar recibidas. (5 puntos)\n",
        "  \n",
        "  \n",
        "2. **Evaluaci贸n de la funci贸n de verosimilitud normal**. Deber谩n proveer una funci贸n que reciba una de las **muestras** del punto 1 y eval煤e la probabilidad que esa muestra provenga de una distribuci贸n normal con par谩metros $\\mu$ y $\\sigma$ (que deber谩n ser enviados a la funci贸n). Deber谩n mostrar ejemplos obtenidos bajo ambos esquemas de muestreo. Por ejemplo, si se crea una muestra normal centrada en $\\mu_1=177$ con $\\sigma_1=1$ y evaluamos la verosimilitud para $\\mu=176,\\sigma=3$ podr铆a darnos una probabilidad alta. En contraposici贸n, al crear una muestra uniforme entre $170$ y $180$ y evaluarla para esos mismos par谩metros de verosimilitud, se esperar铆a que sea menos probable. Todo lo anterior debe reflejarse con ejemplos que muestren el correcto funcionamiento (10 puntos)\n",
        "3. 驴Qu茅 problema ocurre con el c谩lculo de la funci贸n de verosimilitud cuando aumentamos la cantidad de observaciones en varios 贸rdenes de magnitud? y 驴Cual ser铆a una forma de solucionar este problema? Programe una funci贸n con la posible soluci贸n y anote como comentarios las respuestas a las dos preguntas anteriores. De igual forma muestre un ejemplo de como invocar esta funci贸n (10 puntos)\n",
        "4. Implemente una funci贸n para determinar los valores 贸ptimos para maximizar la funci贸n de verosimilitud normal, seg煤n teor铆a vista en clase. Suponga que la cantidad de observaciones (N) siempre es alta. Igualmente se espera que se provean ejemplos en el c贸digo para mostrar el correcto funcionamiento (10 puntos)\n",
        "5. Genere 10000 muestras de 30 observaciones cada una  provenientes de una distribuci贸n normal con $\\mu=170$ y $\\sigma=1$. Calcule el valor 贸ptimo de la varianza para maximizar la funci贸n de verosimilitud normal de cada muestra (estimador de la varianza sesgado) y luego obtenga el valor esperado de la varianza (promedio sobre las 10000 muestras). Compare este valor esperado con el valor  de varianza usado para generar las muestras ($\\sigma^{2}=1$)  . Ejecute varias veces su c贸digo y responda 驴El valor esperado de la varianza aproxima de manera correcta la varianza original  de la distribuci贸n o es necesario hacer alguna correcci贸n en este caso para el c谩lculo del valor 贸ptimo de la varianza? Justifique su respuesta en ambos casos y explique cual ser铆a la correcci贸n en caso afirmativo (10 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uce-mn55xTXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "61548eba-00af-4bf2-e4e7-1f8d43ab0fa5"
      },
      "source": [
        "# EJERCICIO 2.1\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''\n",
        "Returns a sample of random heights with uniform distribution\n",
        "\n",
        "Parameters:\n",
        "  n: number of samples (default: 100)\n",
        "  min_height: sample's minimum height in cm\n",
        "  max_height: sample's maximum height in cm\n",
        "\n",
        "Returns:\n",
        "  numpy vector with all samples in centimeters\n",
        "'''\n",
        "def get_height_samples_uniform(min_height=30, max_height=220, n=100):\n",
        "  samples = np.random.uniform(min_height, max_height + 1, n)\n",
        "\n",
        "  return samples\n",
        "\n",
        "'''\n",
        "Returns a sample of random heights with normal distribution\n",
        "\n",
        "Parameters:\n",
        "  n: number of samples (default: 100)\n",
        "  mean: Mean of the sample's distribution\n",
        "  std_dev: standard deviation of the sample's distribution\n",
        "\n",
        "Returns:\n",
        "  numpy vector with all samples in centimeters\n",
        "'''\n",
        "def get_height_samples_normal(mean=0, std_dev=0.1, n=100):\n",
        "  samples = np.random.normal(mean, std_dev, n)\n",
        "\n",
        "  return samples\n",
        "\n",
        "'''\n",
        "Plots a histogram from the samples vector.\n",
        "\n",
        "Parameters:\n",
        "  samples: Vector with all samples to plot\n",
        "  bins: Number of bins to generate the histogram\n",
        "\n",
        "Returns:\n",
        "  None\n",
        "'''\n",
        "def plot_histogram(samples, bins=9):\n",
        "  if bins > 9:\n",
        "    bins = 9\n",
        "\n",
        "  if bins <= 0:\n",
        "    bins = 1\n",
        "\n",
        "  plt.hist(samples, bins=bins)\n",
        "  plt.show()\n",
        "\n",
        "bins = 9\n",
        "\n",
        "print(\" 100 muestras aleatorias con distribuci贸n UNIFORME, con alturas entre 140cm a 200cm\")\n",
        "uniform_samples = get_height_samples_uniform(min_height=140, max_height=200, n=100)\n",
        "plot_histogram(uniform_samples, bins)\n",
        "\n",
        "print(\" 100 muestras aleatorias con distribuci贸n NORMAL, con media=160cm y desviaci贸n est谩ndar=8cm\")\n",
        "normal_samples = get_height_samples_normal(mean=160, std_dev=8, n=100)\n",
        "plot_histogram(normal_samples, bins)\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 100 muestras aleatorias con distribuci贸n UNIFORME, con alturas entre 140cm a 200cm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            " 100 muestras aleatorias con distribuci贸n NORMAL, con media=160cm y desviaci贸n est谩ndar=8cm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wLypmWaJAVU",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 2.2\n",
        "\n",
        "Evaluaci贸n de la funci贸n de verosimilitud normal. Deber谩n proveer una funci贸n que reciba una de las muestras del punto 1 y eval煤e la probabilidad que esa muestra provenga de una distribuci贸n normal con par谩metros    y    (que deber谩n ser enviados a la funci贸n). Deber谩n mostrar ejemplos obtenidos bajo ambos esquemas de muestreo. Por ejemplo, si se crea una muestra normal centrada en  1=177  con  1=1  y evaluamos la verosimilitud para  =176,=3  podr铆a darnos una probabilidad alta. En contraposici贸n, al crear una muestra uniforme entre  170  y  180  y evaluarla para esos mismos par谩metros de verosimilitud, se esperar铆a que sea menos probable. Todo lo anterior debe reflejarse con ejemplos que muestren el correcto funcionamiento (10 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5SdbED_0xm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "d6bc393a-77a3-4f6c-be04-282460865038"
      },
      "source": [
        "# EJERCICIO 2.2\n",
        "\n",
        "import math\n",
        "\n",
        "'''\n",
        "Calculates the value using a gaussian density function\n",
        "\n",
        "Parameters:\n",
        "  value: value to calculate\n",
        "  mean: mean of the gaussian distribution\n",
        "  std_dev: standard deviation of the gaussian distribution\n",
        "\n",
        "Returns:\n",
        "  number with the calculation on the gaussian density function\n",
        "'''\n",
        "def getGaussianValue(value, mean, std_dev):\n",
        "  variance = std_dev ** 2\n",
        "  norm = 1/(math.sqrt(2 * math.pi * variance))\n",
        "  gaussian = norm * math.exp((-1/(2 * variance)) * (value - mean)**2 )\n",
        "\n",
        "  return gaussian\n",
        "\n",
        "'''\n",
        "Checks the probability of likelihood from a sample with a gaussian density function\n",
        "This function can suffer the underflow issue with big samples\n",
        "\n",
        "Parameters:\n",
        "  samples: vector with all samples to compare\n",
        "  mean: mean of the gaussian distribution\n",
        "  std_dev: standard deviation of the gaussian distribution\n",
        "\n",
        "Returns:\n",
        "  number with the probability of likelihood\n",
        "'''\n",
        "def checkLikelihood(samples, mean, std_dev):\n",
        "  likelihood = 1\n",
        "  for x in samples:\n",
        "    gaussian_x = getGaussianValue(x, mean, std_dev)\n",
        "    likelihood *= gaussian_x\n",
        "\n",
        "  return likelihood\n",
        "\n",
        "\n",
        "likelihood_mean = 170\n",
        "likelihood_std_dev = 5\n",
        "\n",
        "print('Ejercicio 2.2')\n",
        "print('Probabilidad de verosimilitud en diferentes muestras evaluado con media=170 y desviaci贸n est谩ndar=5')\n",
        "\n",
        "print('\\n\\n------\\n\\n')\n",
        "\n",
        "print('Evaluando muestras de una distribuci贸n normal: \\n\\n')\n",
        "\n",
        "print('1. Creados con media=160, desviaci贸n est谩ndar=8 (la probabilidad deber铆a ser baja)')\n",
        "normal_samples = get_height_samples_normal(mean=160, std_dev=8, n=100)\n",
        "print(checkLikelihood(normal_samples, likelihood_mean, likelihood_std_dev))\n",
        "\n",
        "print('\\n\\n2. Creados con media==171, desviaci贸n est谩ndar=4 (la probabilidad deber铆a ser m谩s alta)')\n",
        "normal_samples = get_height_samples_normal(mean=171, std_dev=4, n=100)\n",
        "print(checkLikelihood(normal_samples, likelihood_mean, likelihood_std_dev))\n",
        "\n",
        "print('\\n\\n------\\n\\n')\n",
        "\n",
        "print('Evaluando muestras de una distribuci贸n uniforme: \\n\\n')\n",
        "\n",
        "print('1. Creados con altura m铆nima=140, altura m谩xima=185 (la probabilidad deber铆a ser mucho menor que comparando muestras de distribuci贸n normal)')\n",
        "uniform_samples = get_height_samples_uniform(min_height=140, max_height=185, n=100)\n",
        "print(checkLikelihood(uniform_samples, likelihood_mean, likelihood_std_dev))\n",
        "\n",
        "print('\\n\\n2. Creados con altura m铆nima=160, altura m谩xima=175 (la probabilidad deber铆a ser mejor que la anterior)')\n",
        "uniform_samples = get_height_samples_uniform(min_height=160, max_height=175, n=100)\n",
        "print(checkLikelihood(uniform_samples, likelihood_mean, likelihood_std_dev))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ejercicio 2.2\n",
            "Probabilidad de verosimilitud en diferentes muestras evaluado con media=170 y desviaci贸n est谩ndar=5\n",
            "\n",
            "\n",
            "------\n",
            "\n",
            "\n",
            "Evaluando muestras de una distribuci贸n normal: \n",
            "\n",
            "\n",
            "1. Creados con media=160, desviaci贸n est谩ndar=8 (la probabilidad deber铆a ser baja)\n",
            "7.000979927182151e-280\n",
            "\n",
            "\n",
            "2. Creados con media==171, desviaci贸n est谩ndar=4 (la probabilidad deber铆a ser m谩s alta)\n",
            "7.721624171955924e-124\n",
            "\n",
            "\n",
            "------\n",
            "\n",
            "\n",
            "Evaluando muestras de una distribuci贸n uniforme: \n",
            "\n",
            "\n",
            "1. Creados con altura m铆nima=140, altura m谩xima=185 (la probabilidad deber铆a ser mucho menor que comparando muestras de distribuci贸n normal)\n",
            "2e-323\n",
            "\n",
            "\n",
            "2. Creados con altura m铆nima=160, altura m谩xima=175 (la probabilidad deber铆a ser mejor que la anterior)\n",
            "4.045574729114572e-133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfmN2kJbQKih",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 2.3\n",
        "\n",
        "驴Qu茅 problema ocurre con el c谩lculo de la funci贸n de verosimilitud cuando aumentamos la cantidad de observaciones en varios 贸rdenes de magnitud? y 驴Cual ser铆a una forma de solucionar este problema? Programe una funci贸n con la posible soluci贸n y anote como comentarios las respuestas a las dos preguntas anteriores. De igual forma muestre un ejemplo de como invocar esta funci贸n (10 puntos)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVRPaHLDQRsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b2bf2c65-5a00-4643-e0ee-d6bfa9c8202d"
      },
      "source": [
        "likelihood_mean = 170\n",
        "likelihood_std_dev = 5\n",
        "sample_mean = 170\n",
        "sample_std_dev = 5\n",
        "\n",
        "print('Evaluando verosimilutud con media=160, desviaci贸n=5 en muestras aleatorias normales creadas con media=165, desviaci贸n=4 \\n')\n",
        "normal_samples_10 = get_height_samples_normal(mean=sample_mean, std_dev=sample_std_dev, n=10)\n",
        "print(\"La probabilidad con 10 muestras es de: \", checkLikelihood(normal_samples_10, likelihood_mean, likelihood_std_dev))\n",
        "\n",
        "normal_samples_100 = get_height_samples_normal(mean=sample_mean, std_dev=sample_std_dev, n=100)\n",
        "print(\"La probabilidad con 100 muestras es de: \", checkLikelihood(normal_samples_100, likelihood_mean, likelihood_std_dev))\n",
        "\n",
        "normal_samples_1000 = get_height_samples_normal(mean=sample_mean, std_dev=sample_std_dev, n=1000)\n",
        "print(\"La probabilidad con 1000 muestras es de: \", checkLikelihood(normal_samples_1000, likelihood_mean, likelihood_std_dev))\n",
        "\n",
        "normal_samples_10000 = get_height_samples_normal(mean=sample_mean, std_dev=sample_std_dev, n=10000)\n",
        "print(\"La probabilidad con 10000 muestras es de: \", checkLikelihood(normal_samples_10000, likelihood_mean, likelihood_std_dev))\n",
        "\n",
        "'''\n",
        "Checks the probability of likelihood from a sample with a gaussian density function\n",
        "This function does not suffer the underflow issue with big samples because\n",
        "it's using the natural logarithm to do the calculations\n",
        "\n",
        "Parameters:\n",
        "  samples: vector with all samples to compare\n",
        "  mean: mean of the gaussian distribution\n",
        "  std_dev: standard deviation of the gaussian distribution\n",
        "\n",
        "Returns:\n",
        "  number with the probability of likelihood\n",
        "'''\n",
        "def checkLikelihoodWithLog(samples, mean, std_dev):\n",
        "  likelihood = 0\n",
        "  for x in samples:\n",
        "    gaussian_x = getGaussianValue(x, mean, std_dev)\n",
        "    likelihood += math.log(gaussian_x)\n",
        "\n",
        "  return likelihood\n",
        "\n",
        "print('\\n\\n Ahora evaluando la verosimilutud utilizando logaritmo natural (mismos par谩metros): \\n')\n",
        "print(\"La probabilidad con las mismas 10 muestras es de: \", checkLikelihoodWithLog(normal_samples_10, likelihood_mean, likelihood_std_dev))\n",
        "print(\"La probabilidad con las mismas 100 muestras es de: \", checkLikelihoodWithLog(normal_samples_100, likelihood_mean, likelihood_std_dev))\n",
        "print(\"La probabilidad con las mismas 1000 muestras es de: \", checkLikelihoodWithLog(normal_samples_1000, likelihood_mean, likelihood_std_dev))\n",
        "print(\"La probabilidad con las mismas 10000 muestras es de: \", checkLikelihoodWithLog(normal_samples_10000, likelihood_mean, likelihood_std_dev))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluando verosimilutud con media=160, desviaci贸n=5 en muestras aleatorias normales creadas con media=165, desviaci贸n=4 \n",
            "\n",
            "La probabilidad con 10 muestras es de:  9.011479593528677e-125\n",
            "La probabilidad con 100 muestras es de:  9.837894154327515e-136\n",
            "La probabilidad con 1000 muestras es de:  0.0\n",
            "La probabilidad con 10000 muestras es de:  0.0\n",
            "\n",
            "\n",
            " Ahora evaluando la verosimilutud utilizando logaritmo natural (mismos par谩metros): \n",
            "\n",
            "La probabilidad con las mismas 10 muestras es de:  -285.6246373492998\n",
            "La probabilidad con las mismas 100 muestras es de:  -310.8653309677358\n",
            "La probabilidad con las mismas 1000 muestras es de:  -3039.045486753261\n",
            "La probabilidad con las mismas 10000 muestras es de:  -30194.53807663531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1tn1Qv1SK-I",
        "colab_type": "text"
      },
      "source": [
        "## **R/**\n",
        "\n",
        "Conforme aumenta la cantidad de observaciones se presenta el problema de *underflow*, que significa que computacionalmente la fracci贸n decimal es tan peque帽a que no se puede representar m谩s y termina siendo 0.\n",
        "\n",
        "La soluci贸n es evaluar la funci贸n de verosimilutud utilizando logaritmo natural para maximizar la funci贸n y facilitar los c谩lculos.\n",
        "\n",
        "Como se presenta en los resultados anteriores, ya se puede calcular en muestras de 1.000 y 10.000 observaciones lo cual era imposible utilizando el m茅todo normal de verosimilitud sin usar logaritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INsk84bHXCNC",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 2.4\n",
        "\n",
        "Implemente una funci贸n para determinar los valores 贸ptimos para maximizar la funci贸n de verosimilitud normal, seg煤n teor铆a vista en clase. Suponga que la cantidad de observaciones (N) siempre es alta. Igualmente se espera que se provean ejemplos en el c贸digo para mostrar el correcto funcionamiento (10 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2eT12UQXHMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ddac9664-3da0-4eb8-d2c1-bb28d20d84d0"
      },
      "source": [
        "'''\n",
        "Calculates the optimum mean and standard deviation from a sample\n",
        "\n",
        "Parameters:\n",
        "  samples: vector with all samples to calculate the values\n",
        "  bias: boolean to indicate if the variance estimator should include a bias.\n",
        "        The recommendation is to include the bias only with big samples\n",
        "\n",
        "Returns:\n",
        "  tuple of (optimum mean, optimum standard deviation)\n",
        "'''\n",
        "def get_optimum_values(samples, bias=True):\n",
        "  M = len(samples)\n",
        "\n",
        "  mean_sum = 0\n",
        "  for x in samples:\n",
        "    mean_sum += x\n",
        "  mean = mean_sum / M\n",
        "\n",
        "  variance_sum = 0\n",
        "  for x in samples:\n",
        "    variance_sum += ((x - mean) ** 2)\n",
        "  variance = variance_sum / (M if bias else (M - 1))\n",
        "\n",
        "  return mean, math.sqrt(variance)\n",
        "\n",
        "size_samples = 100\n",
        "mean = 170\n",
        "std_dev = 5\n",
        "\n",
        "normal_samples = get_height_samples_normal(mean=mean, std_dev=std_dev, n=size_samples)\n",
        "\n",
        "optimum_mean, optimum_std_dev = get_optimum_values(normal_samples, bias=True)\n",
        "_, nobias_optimum_std_dev = get_optimum_values(normal_samples, bias=False)\n",
        "\n",
        "print('Con una muestra de 10.000 observaciones, creadas con media=170, desviaci贸n=5, los valores optimos estimados son:')\n",
        "print('\\nMedia 贸ptima: ', optimum_mean)\n",
        "print('\\nDesviaci贸n est谩ndar 贸ptima: ', optimum_std_dev)\n",
        "print('\\nDesviaci贸n est谩ndar 贸ptima (usando estimador de varianza sin sesgo): ', nobias_optimum_std_dev)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Con una muestra de 10.000 observaciones, creadas con media=170, desviaci贸n=5, los valores optimos estimados son:\n",
            "\n",
            "Media 贸ptima:  169.63108396156923\n",
            "\n",
            "Desviaci贸n est谩ndar 贸ptima:  4.979644761691183\n",
            "\n",
            "Desviaci贸n est谩ndar 贸ptima (usando estimador de varianza sin sesgo):  5.0047312920570866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-9bWzESXHW2",
        "colab_type": "text"
      },
      "source": [
        "### Ejercicio 2.5\n",
        "\n",
        "Genere 10000 muestras de 30 observaciones cada una  provenientes de una distribuci贸n normal con $\\mu=170$ y $\\sigma=1$. Calcule el valor 贸ptimo de la varianza para maximizar la funci贸n de verosimilitud normal de cada muestra (estimador de la varianza sesgado) y luego obtenga el valor esperado de la varianza (promedio sobre las 10000 muestras). Compare este valor esperado con el valor  de varianza usado para generar las muestras ($\\sigma^{2}=1$)  . Ejecute varias veces su c贸digo y responda 驴El valor esperado de la varianza aproxima de manera correcta la varianza original  de la distribuci贸n o es necesario hacer alguna correcci贸n en este caso para el c谩lculo del valor 贸ptimo de la varianza? Justifique su respuesta en ambos casos y explique cual ser铆a la correcci贸n en caso afirmativo (10 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFOlydQ4b5rY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "a90776f8-8d3a-42e2-ced9-d1ce26832950"
      },
      "source": [
        "'''\n",
        "Performs a test execution to compare the average variance obtained\n",
        "from samples created with specified mean and standard deviation\n",
        "\n",
        "Parameters:\n",
        "  iterations: number of iterations to test\n",
        "  n: Size of the samples\n",
        "  mean: mean of the samples with normal distribution\n",
        "  std_dev: mean of the samples with normal distribution\n",
        "  bias: boolean to indicate if the variance estimator should include a bias.\n",
        "        The recommendation is to include the bias only with big samples\n",
        "\n",
        "Returns:\n",
        "  number with the average variance from all iterations\n",
        "'''\n",
        "def eval_mean_variance(iterations, n, mean, std_dev, bias=True):\n",
        "  variances = []\n",
        "  for i in range(iterations):\n",
        "    samples = get_height_samples_normal(mean=mean, std_dev=std_dev, n=n)\n",
        "    optimum_mean, optimum_std_dev = get_optimum_values(samples, bias=bias)\n",
        "    variances.append(optimum_std_dev ** 2)\n",
        "  \n",
        "  return np.mean(variances)\n",
        "\n",
        "print('Ejecuci贸n #1 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=10000, n=30, mean=170, std_dev=1, bias=True))\n",
        "\n",
        "print('\\nEjecuci贸n #2 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=10000, n=30, mean=170, std_dev=1, bias=True))\n",
        "\n",
        "print('\\nEjecuci贸n #3 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=1000, n=30, mean=170, std_dev=1, bias=True))\n",
        "\n",
        "print('\\nEjecuci贸n #4 de 10.000 iteraciones con 1000 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=10000, n=1000, mean=170, std_dev=1, bias=True))\n",
        "\n",
        "print('\\n\\nAhora usando estimador de varianza sin sesgo')\n",
        "\n",
        "print('\\nEjecuci贸n #5 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=10000, n=30, mean=170, std_dev=1, bias=False))\n",
        "\n",
        "print('\\nEjecuci贸n #6 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=10000, n=30, mean=170, std_dev=1, bias=False))\n",
        "\n",
        "print('\\nEjecuci贸n #7 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=10000, n=30, mean=170, std_dev=1, bias=False))\n",
        "\n",
        "print('\\nEjecuci贸n #8 de 10.000 iteraciones con 1000 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)')\n",
        "print('Varianza promedio: ', eval_mean_variance(iterations=10000, n=1000, mean=170, std_dev=1, bias=False))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ejecuci贸n #1 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)\n",
            "Varianza promedio:  0.9675525648412849\n",
            "\n",
            "Ejecuci贸n #2 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)\n",
            "Varianza promedio:  0.9655483197601874\n",
            "\n",
            "Ejecuci贸n #3 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)\n",
            "Varianza promedio:  0.9666944624130336\n",
            "\n",
            "Ejecuci贸n #4 de 10.000 iteraciones con 1000 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza sesgado)\n",
            "Varianza promedio:  0.9994400152861576\n",
            "\n",
            "\n",
            "Ahora usando estimador de varianza sin sesgo\n",
            "\n",
            "Ejecuci贸n #5 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)\n",
            "Varianza promedio:  1.0000957158704022\n",
            "\n",
            "Ejecuci贸n #6 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)\n",
            "Varianza promedio:  1.002535412075098\n",
            "\n",
            "Ejecuci贸n #7 de 10.000 iteraciones con 30 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)\n",
            "Varianza promedio:  0.9982685330832359\n",
            "\n",
            "Ejecuci贸n #8 de 10.000 iteraciones con 1000 observaciones, media=170, desviaci贸n=1 (usando estimador de varianza SIN sesgo)\n",
            "Varianza promedio:  0.9991069288745901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ddi93x4d9Ip",
        "colab_type": "text"
      },
      "source": [
        "## **R/**\n",
        "\n",
        "En las 3 primeras ejecuciones donde se utiliz贸 el estimador de varianza sesgado, el valor de la varianza promedio obtenida no aproxima de mejor manera el utilizado para crear las muestras.\n",
        "\n",
        "Al haber pocos datos (solo 30), este estimador se ajusta mucho a los pocos datos que hay y se deberia compensar quitando dicho sesgo. Hay que resaltar que si funcionar铆a si la cantidad de datos es muy grande. Por ejemplo, en la **ejecuci贸n #4**, se sigue utilizando el mismo estimador con sesgo pero con observaciones de 1000 elementos. Como se puede notar, la varianza ahora si aproxima casi por completo la utilizada inicialmente.\n",
        "\n",
        "Para trabajar con pocos datos podemos utilizar el estimador sin sesgo que se adecua mejor. Podemos ver en las **ejecuciones #5, #6 y #7** que con observaciones de 30 datos, la varianza estimada obtenida despues de 10.000 iteraciones si se aproxima muy bien al utilizado en la creaci贸n de las muestras.\n",
        "\n",
        "As铆 mismo, se realiza en la **ejecuci贸n #8** una prueba con el estimador sin sesgo en muestras de 1000 observaciones. Esta tambi茅n se adecua de buena manera."
      ]
    }
  ]
}